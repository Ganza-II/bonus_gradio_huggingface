{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Huggingface and gradio\n",
        "\n",
        "A different library for sharing applications called `gradio` is becoming popular with easy deep learning model integrations.  For this assignment, your goal is to write a basic tutorial that:\n",
        "\n",
        "- Discusses the basics of building a `gradio` app with rows, columns, images, input fields, and sliders.  Demonstrate this with a `gradio` app of your imagination (different than docs creativity matters!).\n",
        "- Demonstrates how to use the huggingface `transformers` library and its pipelines to build a `gradio` app. [here](https://www.gradio.app/guides/using-hugging-face-integrations)\n",
        "\n",
        "Create a github repository with your tutorial notebook and a README with a paragraph overview of the tutorial and description of huggingface model and app."
      ],
      "metadata": {
        "id": "AkpDJCzvh5l6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial Goal\n",
        "Build a basic Gradio app using a Blocks layout (rows/columns), an image, text input fields, and a slider. Then integrate a Hugging Face `transformers` pipeline into the app so user input is processed by a pretrained model and results are displayed in the UI."
      ],
      "metadata": {
        "id": "Vv8Nkl2s3pIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U gradio transformers accelerate torch\n",
        "import gradio as gr\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "tSDsnw-Ji5W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Face transformers pipeline (pretrained sentiment model)\n",
        "sentiment_pipe = pipeline(\n",
        "    task=\"sentiment-analysis\",\n",
        "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "    device=-1  # CPU for Colab stability\n",
        ")\n",
        "\n",
        "def analyze_review(review_text: str, confidence_threshold: float):\n",
        "    \"\"\"\n",
        "    Runs a HF sentiment pipeline and returns:\n",
        "    1) a summary string\n",
        "    2) a 2-class probability dict\n",
        "    3) a threshold-based verdict string\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not review_text or not review_text.strip():\n",
        "            return \"Please enter text.\", {\"NEGATIVE\": 0.0, \"POSITIVE\": 0.0}, \"No text provided.\"\n",
        "\n",
        "        out = sentiment_pipe(review_text[:2000])[0]\n",
        "        label = str(out[\"label\"]).upper()\n",
        "        score = float(out[\"score\"])\n",
        "\n",
        "        if label == \"POSITIVE\":\n",
        "            probs = {\"NEGATIVE\": float(1.0 - score), \"POSITIVE\": score}\n",
        "        else:\n",
        "            probs = {\"NEGATIVE\": score, \"POSITIVE\": float(1.0 - score)}\n",
        "\n",
        "        verdict = (\n",
        "            f\"Meets threshold ({confidence_threshold:.2f}).\"\n",
        "            if score >= confidence_threshold\n",
        "            else f\"Below threshold ({confidence_threshold:.2f}).\"\n",
        "        )\n",
        "\n",
        "        summary = f\"Prediction: {label} (confidence={score:.3f})\"\n",
        "        return summary, probs, verdict\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"ERROR: {type(e).__name__}: {e}\", {\"NEGATIVE\": 0.0, \"POSITIVE\": 0.0}, \"ERROR\"\n"
      ],
      "metadata": {
        "id": "POx8qgOg1rQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio Layout (Rows/Columns, Image, Inputs, Slider).\n",
        "This section builds a Gradio Blocks app using a row/column layout.\n",
        "The left column contains an image, a confidence-threshold slider, and helper controls.\n",
        "The right column contains the main text input and model outputs.\n",
        "Clicking the button runs the Hugging Face pipeline and displays the prediction results."
      ],
      "metadata": {
        "id": "y8-CkgJA3yUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HEADER_IMAGE_URL = \"https://huggingface.co/front/assets/huggingface_logo-noborder.svg\"\n",
        "\n",
        "with gr.Blocks(title=\"HF + Gradio Sentiment Review Console\") as demo:\n",
        "    gr.Markdown(\"# Hugging Face + Gradio: Sentiment Review Console\")\n",
        "    gr.Markdown(\n",
        "        \"This demo uses a Gradio Blocks layout (rows/columns), an image, text inputs, and a slider, \"\n",
        "        \"and integrates a Hugging Face `transformers` pipeline.\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        # LEFT COLUMN: image + controls\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Image(\n",
        "                value=HEADER_IMAGE_URL,\n",
        "                label=\"Header Image (loaded from URL)\",\n",
        "                show_label=True,\n",
        "                height=120\n",
        "            )\n",
        "\n",
        "            threshold = gr.Slider(\n",
        "                minimum=0.50,\n",
        "                maximum=0.99,\n",
        "                value=0.80,\n",
        "                step=0.01,\n",
        "                label=\"Confidence Threshold\"\n",
        "            )\n",
        "\n",
        "            examples = gr.Dropdown(\n",
        "                choices=[\n",
        "                    \"I loved this product. It works perfectly and exceeded expectations.\",\n",
        "                    \"Terrible experience. It broke after one day and support was unhelpful.\",\n",
        "                    \"It's okay. Not great, not awful, but the price is a bit high.\"\n",
        "                ],\n",
        "                value=\"I loved this product. It works perfectly and exceeded expectations.\",\n",
        "                label=\"Quick Examples\"\n",
        "            )\n",
        "            load_example_btn = gr.Button(\"Load Example into Textbox\")\n",
        "            clear_btn = gr.Button(\"Clear\")\n",
        "\n",
        "        # RIGHT COLUMN: main input + outputs\n",
        "        with gr.Column(scale=2):\n",
        "            review = gr.Textbox(\n",
        "                label=\"Paste a review (or type your own)\",\n",
        "                lines=7,\n",
        "                placeholder=\"Type a short review here...\"\n",
        "            )\n",
        "\n",
        "            summary_out = gr.Textbox(label=\"Model Summary\", lines=1)\n",
        "            probs_out = gr.JSON(label=\"Class Probabilities\")\n",
        "            verdict_out = gr.Textbox(label=\"Threshold Verdict\", lines=1)\n",
        "\n",
        "            run_btn = gr.Button(\"Analyze Sentiment\", variant=\"primary\")\n",
        "\n",
        "    # Events / wiring (must be inside Blocks)\n",
        "    load_example_btn.click(fn=lambda x: x, inputs=examples, outputs=review)\n",
        "\n",
        "    run_btn.click(\n",
        "        fn=analyze_review,\n",
        "        inputs=[review, threshold],\n",
        "        outputs=[summary_out, probs_out, verdict_out]\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=lambda: (\"\", \"\", {\"NEGATIVE\": 0.0, \"POSITIVE\": 0.0}, \"\"),\n",
        "        inputs=[],\n",
        "        outputs=[review, summary_out, probs_out, verdict_out]\n",
        "    )\n",
        "\n",
        "# Launch (prevent_thread_lock=True so the cell doesn't run indefinitely in Colab)\n",
        "demo.launch(share=True, debug=False, prevent_thread_lock=True)\n"
      ],
      "metadata": {
        "id": "Q77EeY3213RU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}